{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Node2Vec model using torch geometric with Cora\"\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid # The citation network datasets “Cora”, “CiteSeer” and “PubMed” \n",
    "from torch_geometric.nn import Node2Vec # Import Node2Vec Model\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubMed:  Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n"
     ]
    }
   ],
   "source": [
    "\" **************** IMPORT DATA ********************\"\n",
    "path = os.getcwd() # Directory to download dataset\n",
    "dataset_name = \"PubMed\"\n",
    "dataset = Planetoid(path, dataset_name) # Download the dataset: “Cora”, “CiteSeer” and “PubMed” \n",
    "data = dataset[0] # Tensor representation of the Cora-Planetoid data\n",
    "print(f'{dataset_name}: ', data)\n",
    "\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" **************** CONSTRUCT THE MODEL  ********************\"\n",
    "Node2Vec_model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=20,\n",
    "                     context_size=10, walks_per_node=10,\n",
    "                     num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n",
    "loader = Node2Vec_model.loader(batch_size=100, shuffle=True, num_workers=4) # For batch training\n",
    "optimizer = torch.optim.SparseAdam(list(Node2Vec_model.parameters()), #List of parameters\n",
    "                                   lr = 0.01 # Learning Rate\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" **************** TRAIN FUNCTION ********************\"\n",
    "def train():\n",
    "    Node2Vec_model.train() # Set training as true for the model\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad() # reset of gradient of all variables\n",
    "        loss = Node2Vec_model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss =+ loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" **************** GET EMBEDDING  ********************\"\n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train()\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" **************** PLOT 2D OF EMBEDDED REP   ********************\"\n",
    "@torch.no_grad() # Deactivate autograd functionality\n",
    "def plot_point(colors):\n",
    "    Node2Vec_model.eval() # Evaluate the model based on the trained parameters\n",
    "    z = Node2Vec_model(torch.arange(data.num_nodes, device=device)) # Embedding rep\n",
    "    z = TSNE(n_components=2).fit_transform(z.cpu().numpy())\n",
    "    y = data.y.cpu().numpy()\n",
    "    plt.figure()\n",
    "    for i in range(dataset.num_classes):\n",
    "        plt.scatter(z[y==i,0],z[y==i,1],s=20,color=colors[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "colors = [\n",
    "        '#ffc0cb', '#bada55', '#008080', '#420420', '#7fe5f0', '#065535',\n",
    "        '#ffd700'\n",
    "    ]\n",
    "plot_point(colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" **************** NODE CLASSIFICATION ********************\"\n",
    "def test():\n",
    "    Node2Vec_model.eval() # Evaluate the model based on the trained parameters\n",
    "    z = Node2Vec_model() # Evaluate the model based on the trained parameters\n",
    "    acc = Node2Vec_model.test(z[data.train_mask] ,data.y[data.train_mask],\n",
    "                              z[data.test_mask],data.y[data.test_mask],\n",
    "                              max_iter=150)\n",
    "    return acc\n",
    "\n",
    "print('Accuracy:', test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e11226def484f02b3440b1d3e1a788c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 10248, 26392, 3768, 12020) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:990\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 990\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    991\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Hadia\\OneDrive - University of Calgary\\UniCourses\\01-Special Topics Deep Learning\\Project\\@ClassProject\\nodetoVec.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     loss \u001b[39m=\u001b[39m train()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m02d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m all_vectors \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\Hadia\\OneDrive - University of Calgary\\UniCourses\\01-Special Topics Deep Learning\\Project\\@ClassProject\\nodetoVec.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()  \u001b[39m# put model in train model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m pos_rw, neg_rw \u001b[39min\u001b[39;00m tqdm(loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# set the gradients to 0\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hadia/OneDrive%20-%20University%20of%20Calgary/UniCourses/01-Special%20Topics%20Deep%20Learning/Project/%40ClassProject/nodetoVec.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mloss(pos_rw\u001b[39m.\u001b[39mto(device), neg_rw\u001b[39m.\u001b[39mto(device))  \u001b[39m# compute the loss for the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\site-packages\\tqdm\\notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[1;32m--> 258\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    259\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    260\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    261\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1186\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1185\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1186\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1189\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1152\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1152\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1153\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1154\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Hadia\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1003\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1002\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1003\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1005\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 10248, 26392, 3768, 12020) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "import os.path as osp\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "dataset = 'Cora'\n",
    "path = osp.join('.', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset)  # dowload or load the Cora dataset\n",
    "data = dataset[0]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # check if cuda is available to send the model and tensors to the GPU\n",
    "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=20,\n",
    "                 context_size=10, walks_per_node=10,\n",
    "                 num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n",
    "\n",
    "loader = model.loader(batch_size=128, shuffle=True, num_workers=0)  # data loader to speed the train \n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)  # initzialize the optimizer \n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()  # put model in train model\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in tqdm(loader):\n",
    "        optimizer.zero_grad()  # set the gradients to 0\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))  # compute the loss for the batch\n",
    "        loss.backward()\n",
    "        optimizer.step()  # optimize the parameters\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "\n",
    "all_vectors = \"\"\n",
    "for tensor in model(torch.arange(data.num_nodes, device=device)):\n",
    "    s = \"\\t\".join([str(value) for value in tensor.detach().cpu().numpy()])\n",
    "    all_vectors += s + \"\\n\"\n",
    "# save the vectors\n",
    "with open(\"vectors.txt\", \"w\") as f:\n",
    "    f.write(all_vectors)\n",
    "# save the labels\n",
    "with open(\"labels.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([str(label) for label in data.y.numpy()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c99282d8095a255c9b35c6ff8cfd89e8d0dc73d593c77c936f20370d9959c8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
